# TraMP-Former
This is the PyTorch implementation for: Trajectory-guided Motion Perception for Facial Expression Quality Assessment in Neurological Disorders
[arXiv version](https://arxiv.org/abs/2504.09530)

Code will be updated soon...

We introduce Trajectory-guided Motion Perception Transformer (TraMP-Former), a novel FEQA framework that fuses landmark trajectory features for fine-grained motion capture with visual semantic cues from RGB frames, ultimately regressing the combined features into a quality score.


## Get Started

### Data Download

1: [PFED5 dataset](https://github.com/shuchaoduan/QAFE-Net)

2: [Toronto NeuroFace](https://slp.utoronto.ca/faculty/yana-yunusova/speech-production-lab/datasets/) dataset. 


## Citations
If you find our work useful in your research, please consider giving it a star ‚≠ê and citing our paper in your work:

```
@misc{tramp-former,
      title={Trajectory-guided Motion Perception for Facial Expression Quality Assessment in Neurological Disorders}, 
      author={Shuchao Duan and Amirhossein Dadashzadeh and Alan Whone and Majid Mirmehdi},
      year={2025},
      eprint={2504.09530},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
}

```

To be updated...







